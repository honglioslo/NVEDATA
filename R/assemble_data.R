

#' @title Load metadata for a set of stations
#' @param Vector with stations (if not provided, the default returns all stations available)
#' @return A dataframe with metadata
#' @examples
#' regine_main <- c('1.48','1.49','1.50')
#' metadata <- get_metadata(regine_main)
#' @export

get_metadata <- function(regine_main = meta_data$regine_main) {

  isel <- sapply(regine_main, FUN = function(x) which(meta_data$regine_main == x))

  return(meta_data[isel, ])

}


#' @title Load data for a set of stations, average meteorological grids for the watershed
#' @description Runoff values stored on date yyyy-mm-dd are valid for the period from yyyy-mm-dd 00:00 to yyyy-mm-dd+1 00:00
#' @description Meteorological values stored on date yyyy-mm-dd are valid for the period from yyyy-mm-dd-1 06:00 to yyyy-mm-dd 06:00
#' @param path_met Path to folder with gridded meteorological data (requires netcdf files, and SeNorge version 2.0 and 2.1)
#' @param path_runoff Path to folder with files containing runoff data generated by lescon_var
#' @param regine_main Vector with stations (regine_area and main_no seperated by a full stop)
#' @param time_vec Vector with dates (using format from package lubridate)
#' @examples
#' library(lubridate)
#' path_met <- '//hdata/grid/metdata/met_obs_v2.0'
#' path_runoff <- '//hdata/fou/Vannbalansekart/Data/Runoff_All'
#' regine_main <- c('1.48','1.49','1.50')
#' time_vec <- seq(ymd("2011-01-01"), ymd("2011-01-04"), by = "days")
#' res <- load_data_mean(path_met, path_runoff, regine_main, time_vec)
#' @return A list with data for each station
#' @export

load_data_mean <- function(path_met, path_runoff, regine_main, time_vec) {

  # Test if metadata exist for stations

  if (!all(regine_main %in% meta_data$regine_main)) {

    imissing <- !(regine_main %in% meta_data$regine_main)

    station_str <- paste(regine_main[imissing], collapse = ", ")

    stop(paste("Lacking metadata for station", station_str, sep = " "))

  }

  # Initilize list for one station

  init_list <- function(regine_main_in) {

    # Link meta_data and wsh_index

    irow <- which(meta_data$regine_main == regine_main_in)

    drainage_basin_key <- as.character(meta_data$drainage_basin_key[irow])

    # Initilize list

    data_all <- list(time_vec = time_vec,
                     regine_main = regine_main_in,
                     wsh_index = wsh_index[[drainage_basin_key]],
                     metadata = dplyr::filter(meta_data, regine_main == regine_main_in),
                     Tair = NA, Prec = NA)

  }

  # Assign variable to general data structure

  assign_var <- function(istat, iday, variable) {

    data_all[[istat]][[variable]][iday] <- met_data[[istat]]
    data_all[[istat]]

  }

  # Initlize data structure

  data_all <- lapply(regine_main, init_list)

  # Loop over time

  for (iday in seq_along(time_vec)) {


    print(paste("Processing day ", iday, sep = ""))


    # Process air temperature data

    filename <- paste(path_met, "/tm/", format(time_vec[iday], "%Y"), "/tm_", format(time_vec[iday], "%Y_%m_%d"), ".nc", sep = "")

    met_data <- read_nc_file(filename)


#     filename <- paste(path_met, "/tm/", format(time_vec[iday], "%Y"), "/tm_", format(time_vec[iday], "%Y_%m_%d"), ".bil", sep = "")
#
#     met_data <- read_bil_file(filename)
#
#     met_data <- met_data/10 - 273.15



    # Extract data for stations

    met_data <- lapply(regine_main, load_single_wsh, grid_data = met_data)

    # Average data

    met_data <- lapply(met_data, mean)

    # Assign variable to data structure

    data_all <- lapply(seq_along(data_all), assign_var, iday = iday, variable = "Tair")


    # Process precipitation data

    filename <- paste(path_met, "/rr/", format(time_vec[iday], "%Y"), "/rr_", format(time_vec[iday], "%Y_%m_%d"), ".nc", sep = "")

    met_data <- read_nc_file(filename)


#     filename <- paste(path_met, "/rr/", format(time_vec[iday], "%Y"), "/rr_", format(time_vec[iday], "%Y_%m_%d"), ".bil", sep = "")
#
#     met_data <- read_bil_file(filename)
#
#     met_data <- met_data/10



    # Extract data for stations

    met_data <- lapply(regine_main, load_single_wsh, grid_data = met_data)

    # Average data

    met_data <- lapply(met_data, mean)

    # Assign variable to data structure

    data_all <- lapply(seq_along(data_all), assign_var, iday = iday, variable = "Prec")

  }

  # Get runoff data

  data_all <- lapply(data_all,load_runoff_all, path = path_runoff, time = time_vec)

  return(data_all)

}



#' @title Load data for a set of stations, aggregate meteorological grids for the watershed into 200m elevation bands
#' @description Runoff values stored on date yyyy-mm-dd are valid for the period from yyyy-mm-dd 00:00 to yyyy-mm-dd+1 00:00
#' @description Meteorological values stored on date yyyy-mm-dd are valid for the period from yyyy-mm-dd-1 06:00 to yyyy-mm-dd 06:00
#' @param path_met Path to folder with gridded meteorological data (requires netcdf files, and SeNorge version 2.0 and 2.1)
#' @param path_runoff Path to folder with files containing runoff data generated by lescon_var
#' @param regine_main Vector with stations (regine_area and main_no seperated by a full stop)
#' @param time_vec Vector with dates (using format from package lubridate)
#' @examples
#' library(lubridate)
#' path_met <- '//hdata/grid/metdata/met_obs_v2.0'
#' path_runoff <- '//hdata/fou/Vannbalansekart/Data/Runoff_All'
#' regine_main <- c('1.48','1.49','1.50')
#' time_vec <- seq(ymd("2011-01-01"), ymd("2011-01-04"), by = "days")
#' res <- load_data_elev(path_met, path_runoff, regine_main, time_vec)
#' @return A list with data for each station
#' @export

load_data_elev <- function(path_met, path_runoff, regine_main, time_vec) {

  # Test if metadata exist for stations

  if (!all(regine_main %in% meta_data$regine_main)) {

    imissing <- !(regine_main %in% meta_data$regine_main)

    station_str <- paste(regine_main[imissing], collapse = ", ")

    stop(paste("Lacking metadata for station", station_str, sep = " "))

  }

  # Initilize list for one station

  init_list <- function(regine_main_in) {

    # Link meta_data and wsh_index

    irow <- which(meta_data$regine_main == regine_main_in)

    drainage_basin_key <- as.character(meta_data$drainage_basin_key[irow])

    # Compute mean elevation and fraction of total area for each elevation band

    elev <- dem_vec[wsh_index[[drainage_basin_key]]]
    elev_zones <- cut(elev, breaks = seq(-200,4000,200), right = FALSE)
    elev_mean <- aggregate(elev, by = list(elev_zones), FUN = mean)
    elev_frac <- aggregate(rep(1, length(elev)), by = list(elev_zones), FUN = sum)
    elev_frac <- elev_frac$x / length(elev)

    # Initilize list

    data_all <- list(time_vec = time_vec,
                     regine_main = regine_main_in,
                     elev_mean = elev_mean$x,
                     frac_elev_band = elev_frac,
                     wsh_index = wsh_index[[drainage_basin_key]],
                     metadata = dplyr::filter(meta_data, regine_main == regine_main_in),
                     Tair = matrix(NA, nrow = length(time_vec) , ncol = length(elev_mean$x)),
                     Prec = matrix(NA, nrow = length(time_vec) , ncol = length(elev_mean$x)))
  }


  # Aggregate meteorological data over elevation zones

  aggregate_elevations <- function(met_data, data_all) {

    elev_wsh <- dem_vec[data_all$wsh_index]
    elev_as_factors <- cut(elev_wsh, breaks = seq(-200,4000,200), right = FALSE)
    res <- aggregate(met_data, by = list(elev_as_factors), FUN = mean)

    return(res$x)

  }

  # Assign variable to general data structure

  assign_var <- function(istat, iday, variable) {

    data_all[[istat]][[variable]][iday, ] <- met_data[[istat]]
    data_all[[istat]]

  }

  # Initlize data structure

  data_all <- lapply(regine_main, init_list)

  # Loop over time

  for (iday in seq_along(time_vec)) {


    print(paste("Processing day ", iday, sep = ""))


    # Process air temperature data

    filename <- paste(path_met, "/tm/", format(time_vec[iday], "%Y"), "/tm_", format(time_vec[iday], "%Y_%m_%d"), ".nc", sep = "")

    met_data <- read_nc_file(filename)

#     filename <- paste(path_met, "/tm/", format(time_vec[iday], "%Y"), "/tm_", format(time_vec[iday], "%Y_%m_%d"), ".bil", sep = "")
#
#     met_data <- read_bil_file(filename)
#
#     met_data <- met_data/10 - 273.15

    # Extract data for stations

    met_data <- lapply(regine_main, load_single_wsh, grid_data = met_data)

    # Aggregate data

    met_data <- mapply(aggregate_elevations, met_data, data_all, SIMPLIFY = FALSE)

    # Assign variable to data structure

    data_all <- lapply(seq_along(data_all), assign_var, iday = iday, variable = "Tair")


    # Process precipitation data

    filename <- paste(path_met, "/rr/", format(time_vec[iday], "%Y"), "/rr_", format(time_vec[iday], "%Y_%m_%d"), ".nc", sep = "")

    met_data <- read_nc_file(filename)

#     filename <- paste(path_met, "/rr/", format(time_vec[iday], "%Y"), "/rr_", format(time_vec[iday], "%Y_%m_%d"), ".bil", sep = "")
#
#     met_data <- read_bil_file(filename)
#
#     met_data <- met_data/10

    # Extract data for stations

    met_data <- lapply(regine_main, load_single_wsh, grid_data = met_data)

    # Aggregate data

    met_data <- mapply(aggregate_elevations, met_data, data_all, SIMPLIFY = FALSE)

    # Assign variable to data structure

    data_all <- lapply(seq_along(data_all), assign_var, iday = iday, variable = "Prec")

  }

  # Get runoff data

  data_all <- lapply(data_all,load_runoff_all, path = path_runoff, time = time_vec)

  invisible(data_all)

}




##-----
# HACK FLO

#' @title Load flood data for a set of stations
#' @description Loads flood forecasting data for all available models
#' @param path_met Path to folder with gridded meteorological data (requires netcdf files, and SeNorge version 2.0 and 2.1)
#' @param path_runoff Path to folder with files containing runoff data generated by lescon_var
#' @param regine_main Vector with stations (regine_area and main_no seperated by a full stop).
#' Default is meta_data$regine_main from the packaged meta_data
#' @param time_vec Vector with dates (using format from package lubridate)
#' @examples
#' regine_main <- c('1.48','1.49','1.50')
#' res <- load_flood_data(regine_main)
#' # Or to run for every station:
#' res <- load_flood_data(meta_data$regine_main)
#' # To see some which stations should have been modelled do:
#' which(meta_data$br23_HBV == "Y")
#' # Most of them should work now. Let me know the ones which don't!
#' res[[41]]$HBV$modelled
#' # To plot with the dates, we have to use the lubridate package
#' library('lubridate')
#' plot(ymd(res[[41]]$HBV$time_vec), res[[41]]$HBV$modelled)
#' @return Nothing Only saves .rda files to the working directory
#' @import tidyr
#' @import reshape
#' @export

load_flood_data <- function(regine_main = meta_data$regine_main) {

  # Test if metadata exist for stations
  if (!all(regine_main %in% meta_data$regine_main)) {

    imissing <- !(regine_main %in% meta_data$regine_main)

    station_str <- paste(regine_main[imissing], collapse = ", ")

    stop(paste("Lacking metadata for station", station_str, sep = " "))

  }

  ## Command when running it from the package
  HBV_2014 <- read_HBV_data(filename = '//hdata/drift/flom/usikkerhet_grd/utskrift/vfpost_usikkerhet.txt')
  HBV_2016_INIT <- read_HBV_data(filename = '//hdata/drift/flom/usikkerhet_grd/ut_test/vfpost_usikkerhet.txt')
  # Elin doesn't want to plot L50, H50, L90, H90
  HBV_2016_INIT <- subset(HBV_2016_INIT, select = - c(modelled_L50, modelled_L90, modelled_H50, modelled_H90))

  HBV_2016_PRECIP_CORRECTION <- read_HBV_P(filename = '//hdata/drift/flom/usikkerhet_grd/ut_test/vfp3030.txt')
  DDD <- read_DDD(filename = '//hdata/drift/flom//DDD24h2015R/24hres.txt')
  flomtabell <- read_flomtabell()
  HBV_past_year <- read_past_HBV()
  # Reshape the HBV_past_year into a dataframe. This is brutal and slow but allows having the same structure as the previous data
  HBV_past_year <- reshape::merge_all(HBV_past_year)

    # Create the long data frame to be later used by ggplot
  HBV_2014 <- tidyr::gather(HBV_2014, key = Tmp, value = Values, -time, -regine.main, -station.name) %>%
    tidyr::separate(Tmp, into = c("Type", "Variable"), sep = "_")

  HBV_2016 <- dplyr::right_join(HBV_2016_INIT, HBV_2016_PRECIP_CORRECTION, by = c("regine.main", "time"))
  HBV_2016 <- tidyr::gather(HBV_2016, key = Tmp, value = Values, -time, -regine.main, -station.name) %>%
    tidyr::separate(Tmp, into = c("Type", "Variable"), sep = "_")

  DDD <- tidyr::gather(DDD, key = Tmp, value = Values, -time, -regine.main) %>%
    tidyr::separate(Tmp, into = c("Type", "Variable"), sep = "_")

  flomtabell <- tidyr::gather(flomtabell, key = Tmp, value = Values, -regine.main) %>%
    tidyr::separate(Tmp, into = c("Type", "Variable"), sep = "_")

  HBV_past_year <- tidyr::gather(HBV_past_year, key = Tmp, value = Values, -time, -regine.main) %>%
    tidyr::separate(Tmp, into = c("Type", "Variable"), sep = "_")

  # Initilize list for one station
  init_list <- function(regine_main_in) {


    data_all <- list(regine_main = regine_main_in,
                     metadata = dplyr::filter(meta_data, regine_main == regine_main_in),
                     # observed = observed,
#                      DDM = dplyr::filter(DDM_data, regine_main == regine_main_in),
                     DDD = dplyr::filter(DDD, regine.main == regine_main_in),
                     # ODM = dplyr::filter(ODM_data, regine_main == regine_main_in),
                      HBV_2014 = dplyr::filter(HBV_2014, regine.main == regine_main_in),
                      HBV_2016 = dplyr::filter(HBV_2016, regine.main == regine_main_in)
)

  }

  # Fill up with all stations specified in input argument (lapply over level 1, all stations)
  data_all <- lapply(regine_main, init_list)

  # Save the files to the working directory for later use in Shiny app
  save(data_all, file = paste(getwd(),"/","data_all.RData", sep = ""))

  save(meta_data, file = paste(getwd(),"/","meta_data.rda", sep = ""))
  save(HBV_2014, file = paste(getwd(),"/","HBV_2014.RData", sep = ""))
  save(HBV_2016, file = paste(getwd(),"/","HBV_2016.RData", sep = ""))
  save(DDD, file = paste(getwd(),"/", "DDD.RData", sep = ""))
  save(flomtabell, file = paste(getwd(),"/", "flomtabell.RData", sep = ""))
  save(HBV_past_year, file = paste(getwd(),"/", "HBV_past_year.RData", sep = ""))

  # invisible(data_all)

}
